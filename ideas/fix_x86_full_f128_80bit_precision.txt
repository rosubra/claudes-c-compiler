Full 80-bit precision for x86 long double (F128)

Status: Partially done. Casts and binops now use x87 FPU, but the f64 register
intermediate still limits precision.

Problem:
The x86 backend stores F128 values as f64 bit-patterns in %rax registers,
converting to/from x87 80-bit format only for memory load/store. This means:
1. Values that exceed f64's 53-bit mantissa lose precision when passing
   through registers (e.g., INT64_MAX as long double)
2. Constants like LDBL_MIN (3.36e-4932) underflow to 0.0 in f64
3. x87 intermediate precision in binops helps but can't recover already-lost data

Known failure cases:
- islessgreater with LDBL_MIN (underflows to 0 in f64)
- long long -= long double (i64 precision loss)
- Other long double precision-sensitive operations

Solution approaches (from easiest to hardest):

A) Memory-based F128 protocol (recommended):
   Instead of f64 bits in %rax, F128 values would be stored in stack alloca
   slots in 80-bit format. Operations would load/store directly from/to these
   slots using fldt/fstpt. Register "values" for F128 would be pointers to
   the stack slots. This requires:
   - New F128 alloca allocation in codegen state
   - Modified operand_to_rax for F128: loads into x87 ST0 instead
   - Modified store_rax_to for F128: stores from ST0 via fstpt
   - All F128 operations work directly on x87 stack
   - ~500 LOC change estimate

B) x87 stack-based protocol:
   F128 values live in x87 FPU registers (ST0-ST7). Limited to 8 live values
   but sufficient for most code. Requires tracking x87 stack depth.
   More complex than A, harder to integrate with existing register allocator.

C) Hybrid approach:
   Keep f64 in registers for most operations, but add special IR annotations
   for F128 operations that need full precision. The codegen would fuse
   cast+store and load+binop patterns to avoid the f64 intermediate when
   the full chain is F128.

To verify: test islessgreater with LDBL_MIN and long long -= long double.
